# openclaw-trace (prototype)

> **NOTE (AI-GENERATED, UNREVIEWED):** This repository was generated by LLMs as a quick prototype. Expect rough edges.

An **RLM-inspired trace crawler** for **OpenClaw / Clawdbot**-style session transcripts (JSONL).

Main use: crawl a directory of traces and **mine candidate “frontier experiment” ideas** from patterns in real agent work.

This project intentionally follows the "recursive-llm" pattern:
- The transcript is loaded into a Python object (`Transcript.events`) **outside the model prompt**.
- The model only sees *small slices* via helper functions like `search()` and `window()`.
- The model returns **Python code only**.
- The driver executes that code in a constrained environment, expecting `FINAL` and optionally `PHASES`.

## Install

```bash
cd /home/debian/clawd/home/rlm-session-analyzer
python -m venv .venv
source .venv/bin/activate
pip install -U pip
pip install -e .
```

## Run (with an OpenAI-compatible API)

Set API credentials:

```bash
export OPENAI_API_KEY="..."
# optional
export OPENAI_MODEL="gpt-4.1-mini"
export OPENAI_BASE_URL="https://api.openai.com/v1"
```

Analyze a single transcript:

```bash
openclaw-trace analyze /path/to/session.jsonl \
  --objective "Reconstruct phases/branches/failures of creating a research paper" \
  --out analysis.json
```

The output is JSON with a top-level `result` containing:
- `FINAL`: narrative summary
- `PHASES`: structured phase list (if produced)

## Mine research ideas across many traces

This mode crawls a directory of `.jsonl` traces, does a lightweight keyword scan, builds short synopses, and (optionally) asks an OpenAI-compatible LLM to propose **frontier experiment ideas**.

Outputs are short summaries (not full transcripts). If you need privacy guarantees, add your own redaction step.

Example invocation:

```bash
openclaw-trace mine-ideas \
  --sessions-dir /home/debian/.clawdbot/agents/main/sessions \
  --include "**/*.jsonl" \
  --exclude "**/node_modules/**" \
  --max-sessions 200 \
  --no-llm \
  --out-json out_mine_ideas.json \
  --out-md out_mine_ideas.md
```

To enable LLM idea generation, omit `--no-llm` and set `OPENAI_API_KEY`.

## Mine self-improvement signals (errors, frustration, suggestions)

This mode crawls traces and asks an LLM to emit **grounded** signal items with short evidence quotes. v1 includes a PII redaction stub only (no redaction yet).

Example invocation (LLM disabled, heuristic-only):

```bash
openclaw-trace mine-signals \
  --sessions-dir /home/debian/.clawdbot/agents/main/sessions \
  --include "**/*.jsonl" \
  --max-sessions 50 \
  --llm none \
  --out-jsonl out_signals.jsonl \
  --out-json out_signals.json
```

## Research briefs (template + headless runner)

Template:

```
docs/research-briefs/BRIEF_TEMPLATE.md
```

Headless runner (Claude Code + optional Codex critic):

```bash
python scripts/run_research_brief.py \
  --ticket-id 145 \
  --context /home/debian/clawd/home/tmp/out_signals_latest120.json \
  --critic
```

Use `--dry-run` to print the assembled prompt without calling Claude.

## Run (no API key)

If `OPENAI_API_KEY` is missing, the tool falls back to a deterministic stub.

You can still use it by supplying your own analysis program:

```bash
openclaw-trace analyze /path/to/session.jsonl --llm none --program examples/paper_program.py
```

## Writing a custom analyzer program

The executed program **cannot import** or access filesystem/network. You are expected to use these helpers:

- `search(query, fields=None, limit=..., start=0) -> list[dict]`
- `window(start, end, fields=None) -> list[dict]`
- `detect_tool_calls(start=0, end=None) -> list[dict]`
- `detect_failures(start=0, end=None, limit=200) -> list[dict]`
- `summarize_span(start, end) -> str`
- `N` total number of events

Your program should set:

- `FINAL: str` (required)
- `PHASES: list[dict]` (optional)

See `examples/paper_program.py`.

## Notes / Limitations

- The sandbox (`safe_exec.py`) is a *best-effort guardrail*, not a perfect security boundary.
- `detect_tool_calls` / `detect_failures` are heuristic; different transcript schemas may require tweaks.
- For extremely large transcripts, this loads everything into memory. If that’s a problem, the next step is an on-disk index + lazy windows.

## Design notes (future mapping to alexzhang13/rlm)

See `DESIGN_NOTES.md` for how to scale this into a fuller RLM workflow (planner/controller + tool registry + caching).
